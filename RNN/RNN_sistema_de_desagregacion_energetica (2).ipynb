{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BLOQUE 1: ImportaciÃ³n y ConfiguraciÃ³n\n",
        "# ==========================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "#importaciÃ³n de dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/munevardo/graduation_project/refs/heads/main/Data_Greener_all.csv\")\n",
        "\n",
        "# 1. Definimos las variables de entrada (Lo que sabe el modelo)\n",
        "# 'Total' es el consumo global de la casa, mÃ¡s las variables de tiempo.\n",
        "features_cols = [\"Total\", \"hora\", \"DiaSemanaNum\", \"Mes\"]\n",
        "\n",
        "# 2. Definimos las cargas que queremos desagregar (Lo que va a predecir)\n",
        "targets_list = [\"Ventilation\", \"Sokets plug\", \"Lighting\", \"Other electricity\", \"Cooling\", \"Heating\"]\n",
        "\n",
        "# 3. ConfiguraciÃ³n de la RNN\n",
        "TIME_STEPS = 24  # El modelo mirarÃ¡ las Ãºltimas 24 horas para decidir\n",
        "EPOCHS = 15      # CuÃ¡ntas veces repasa los datos (puedes subirlo a 30-50 para mejorar)\n",
        "BATCH_SIZE = 64  # CuÃ¡ntos datos procesa de golpe\n",
        "\n",
        "# Lista vacÃ­a para guardar los resultados finales de cada carga\n",
        "results_list = []\n",
        "\n",
        "print(\"âœ… ConfiguraciÃ³n lista. Targets a analizar:\", targets_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F_sAl0suUt3",
        "outputId": "9dd38fc9-6a5d-4f7b-9d0b-cbf7ac65212c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ConfiguraciÃ³n lista. Targets a analizar: ['Ventilation', 'Sokets plug', 'Lighting', 'Other electricity', 'Cooling', 'Heating']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar variables\n",
        "\n",
        "# 1. Convertir Time a datetime\n",
        "df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\")\n",
        "\n",
        "# 2. Convertir las demÃ¡s columnas a numÃ©rico\n",
        "cols_numericas = [\"Ventilation\", \"Sokets plug\", \"Lighting\", \"Other electricity\", \"Cooling\", \"Heating\"]\n",
        "df[cols_numericas] = df[cols_numericas].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Verificar cambios\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci1FIaPGvkXo",
        "outputId": "4bc5e745-65b0-41dd-9106-5a6533878eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time                 datetime64[ns]\n",
            "Ventilation                 float64\n",
            "Sokets plug                 float64\n",
            "Lighting                    float64\n",
            "Other electricity           float64\n",
            "Cooling                     float64\n",
            "Heating                     float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\")\n",
        "\n",
        "# Crear nuevas columnas\n",
        "df['hora'] = df[\"Time\"].dt.hour\n",
        "df[\"Dia\"] = df[\"Time\"].dt.day\n",
        "df[\"Mes\"] = df[\"Time\"].dt.month\n",
        "df[\"Anno\"] = df[\"Time\"].dt.year\n",
        "df[\"DiaSemanaNum\"] = df[\"Time\"].dt.weekday   # 0 = Lunes, 6 = Domingo\n",
        "df[\"DiaSemana\"] = df[\"Time\"].dt.day_name()   # Nombre del dÃ­a\n",
        "\n",
        "\n",
        "df[\"Total\"] = (\n",
        "    df[\"Ventilation\"]\n",
        "    + df[\"Sokets plug\"]\n",
        "    + df[\"Lighting\"]\n",
        "    + df[\"Other electricity\"]\n",
        "    + df[\"Cooling\"]\n",
        "    + df[\"Heating\"]\n",
        ")\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU8QeMUGvozZ",
        "outputId": "aca34aa5-5b32-477b-b7c5-9e55c9743dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Time  Ventilation  Sokets plug  Lighting  Other electricity  \\\n",
            "0 2017-01-03 13:00:00         27.4         41.8      53.7               89.6   \n",
            "1 2017-01-03 14:00:00         21.6         37.5      50.9               64.6   \n",
            "2 2017-01-03 15:00:00         18.5         37.4      60.1               64.2   \n",
            "3 2017-01-03 16:00:00         29.7         38.0      52.6               43.2   \n",
            "4 2017-01-03 17:00:00         16.7         38.1      56.7               42.4   \n",
            "\n",
            "   Cooling  Heating  hora  Dia  Mes  Anno  DiaSemanaNum DiaSemana  Total  \n",
            "0     18.6    498.0    13    3    1  2017             1   Tuesday  729.1  \n",
            "1     61.9    500.0    14    3    1  2017             1   Tuesday  736.5  \n",
            "2     16.5    480.0    15    3    1  2017             1   Tuesday  676.7  \n",
            "3     19.8    390.0    16    3    1  2017             1   Tuesday  573.3  \n",
            "4     15.2    373.0    17    3    1  2017             1   Tuesday  542.1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: FunciÃ³n de Ventanas de Tiempo\n",
        "\n",
        "Esta es la funciÃ³n auxiliar que transforma el dataset en \"secuencias\" tridimensionales que la **LSTM** puede entender.\n"
      ],
      "metadata": {
        "id": "bL9jIdxcufwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BLOQUE 2: FunciÃ³n Generadora de Secuencias\n",
        "# ==========================================\n",
        "\n",
        "def create_sequences(X, y, time_steps=TIME_STEPS):\n",
        "    \"\"\"\n",
        "    Transforma datos planos en ventanas de tiempo.\n",
        "    Entrada: (1000 datos, 5 variables)\n",
        "    Salida:  (976 ventanas, 24 pasos de tiempo, 5 variables)\n",
        "    \"\"\"\n",
        "    Xs, ys = [], []\n",
        "\n",
        "    # Recorremos los datos dejando un margen para la ventana\n",
        "    for i in range(len(X) - time_steps):\n",
        "        # Guardamos la ventana de 'time_steps' horas\n",
        "        Xs.append(X[i:(i + time_steps)])\n",
        "        # Guardamos el valor objetivo justo despuÃ©s de la ventana\n",
        "        ys.append(y[i + time_steps])\n",
        "\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "print(\"âœ… FunciÃ³n de secuencias definida correctamente.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrr9lyQBu0FD",
        "outputId": "88467099-dc05-47b3-ddfc-829f42cd3005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FunciÃ³n de secuencias definida correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: El Bucle de entrenamiento por categorÃ­a\n",
        "\n",
        "Empezamos a Itera automÃ¡ticamente por cada categorÃ­a de desagregaciÃ³n, prepara sus datos especÃ­ficos, entrena una red nueva desde cero y evalÃºa su rendimiento."
      ],
      "metadata": {
        "id": "JBDeoaZQvB88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# BLOQUE 3: Bucle de Entrenamiento Automatizado\n",
        "# ==========================================\n",
        "\n",
        "print(\"ğŸš€ Iniciando el anÃ¡lisis masivo de cargas...\\n\")\n",
        "\n",
        "for target_col in targets_list:\n",
        "    print(f\"ğŸ”„ Procesando carga: {target_col.upper()}...\")\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # A. PREPARACIÃ“N DE DATOS ESPECÃFICA\n",
        "    # ---------------------------------------------------------\n",
        "    # Filtramos solo las features + la columna objetivo actual\n",
        "    data = df[features_cols + [target_col]].values\n",
        "\n",
        "    # Escalamos todo entre 0 y 1 (Vital para redes neuronales)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    # Separamos Entradas (X) y Salida (y) dentro de la matriz escalada\n",
        "    # X = Todas las columnas menos la Ãºltima\n",
        "    # y = La Ãºltima columna (la carga actual)\n",
        "    X_scaled = data_scaled[:, :-1]\n",
        "    y_scaled = data_scaled[:, -1]\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # B. DIVISIÃ“N CRONOLÃ“GICA (NO ALEATORIA)\n",
        "    # ---------------------------------------------------------\n",
        "    # Entrenamos con el 80% del pasado, probamos con el 20% del futuro\n",
        "    train_size = int(len(data_scaled) * 0.8)\n",
        "\n",
        "    # Datos crudos divididos\n",
        "    X_train_raw, X_test_raw = X_scaled[:train_size], X_scaled[train_size:]\n",
        "    y_train_raw, y_test_raw = y_scaled[:train_size], y_scaled[train_size:]\n",
        "\n",
        "    # Convertimos a secuencias 3D usando la funciÃ³n del Paso 2\n",
        "    X_train, y_train = create_sequences(X_train_raw, y_train_raw, TIME_STEPS)\n",
        "    X_test, y_test = create_sequences(X_test_raw, y_test_raw, TIME_STEPS)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # C. ARQUITECTURA DE LA RED NEURONAL\n",
        "    # ---------------------------------------------------------\n",
        "    # Limpiamos la memoria de Keras para no mezclar modelos anteriores\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    model = Sequential()\n",
        "    # Capa 1: LSTM que devuelve secuencias (para que la siguiente capa entienda el tiempo)\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    model.add(Dropout(0.2)) # Apaga neuronas al azar para evitar memorizaciÃ³n (overfitting)\n",
        "\n",
        "    # Capa 2: LSTM que comprime la informaciÃ³n\n",
        "    model.add(LSTM(units=30, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Capa de Salida: Predice 1 solo valor (Watts)\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # D. ENTRENAMIENTO\n",
        "    # ---------------------------------------------------------\n",
        "    # verbose=0 hace que no imprima todas las lÃ­neas de entrenamiento para no ensuciar la pantalla\n",
        "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.1, verbose=0, shuffle=False)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # E. PREDICCIÃ“N Y DES-ESCALADO\n",
        "    # ---------------------------------------------------------\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "    # Truco para invertir el escalado:\n",
        "    # El scaler espera todas las columnas original, asÃ­ que creamos matrices \"dummy\" (falsas)\n",
        "\n",
        "    # 1. Des-escalar Predicciones\n",
        "    dummy_pred = np.zeros((len(y_pred), data.shape[1])) # Matriz vacÃ­a del tamaÃ±o original\n",
        "    dummy_pred[:, -1] = y_pred.flatten()                # Ponemos nuestra predicciÃ³n en la Ãºltima columna\n",
        "    pred_inverse = scaler.inverse_transform(dummy_pred)[:, -1] # Transformamos y recuperamos solo la columna final\n",
        "\n",
        "    # 2. Des-escalar Datos Reales (Para comparar peras con peras)\n",
        "    dummy_real = np.zeros((len(y_test), data.shape[1]))\n",
        "    dummy_real[:, -1] = y_test\n",
        "    y_test_inverse = scaler.inverse_transform(dummy_real)[:, -1]\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # F. CÃLCULO DE MÃ‰TRICAS Y GUARDADO\n",
        "    # ---------------------------------------------------------\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_inverse, pred_inverse))\n",
        "    r2 = r2_score(y_test_inverse, pred_inverse)\n",
        "\n",
        "    # Guardamos en la lista\n",
        "    results_list.append({\n",
        "        \"Carga\": target_col,\n",
        "        \"RMSE (Watts)\": round(rmse, 2),\n",
        "        \"R2 Score\": round(r2, 4)\n",
        "    })\n",
        "\n",
        "    print(f\"   ---> Terminado. RÂ²: {r2:.4f} | Error (RMSE): {rmse:.2f} W\\n\")\n",
        "\n",
        "print(\"ğŸ Â¡AnÃ¡lisis de todas las cargas completado!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdffv94du9PE",
        "outputId": "11a45edb-b992-4430-9433-0839301cdd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Iniciando el anÃ¡lisis masivo de cargas...\n",
            "\n",
            "ğŸ”„ Procesando carga: VENTILATION...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---> Terminado. RÂ²: 0.2541 | Error (RMSE): 33.73 W\n",
            "\n",
            "ğŸ”„ Procesando carga: SOKETS PLUG...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---> Terminado. RÂ²: 0.0278 | Error (RMSE): 47.90 W\n",
            "\n",
            "ğŸ”„ Procesando carga: LIGHTING...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---> Terminado. RÂ²: 0.6278 | Error (RMSE): 8.04 W\n",
            "\n",
            "ğŸ”„ Procesando carga: OTHER ELECTRICITY...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---> Terminado. RÂ²: -12.7106 | Error (RMSE): 135.59 W\n",
            "\n",
            "ğŸ”„ Procesando carga: COOLING...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---> Terminado. RÂ²: 0.1270 | Error (RMSE): 53.48 W\n",
            "\n",
            "ğŸ”„ Procesando carga: HEATING...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ---> Terminado. RÂ²: 0.1339 | Error (RMSE): 107.28 W\n",
            "\n",
            "ğŸ Â¡AnÃ¡lisis de todas las cargas completado!\n"
          ]
        }
      ]
    }
  ]
}